{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2-1: How many decision trees exist with n binary attributes?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2^(2^n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2-2 : What is the entropy of the output Y?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import os\n",
    "from math import log, e\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C  Y\n",
      "0  0  1  1  0\n",
      "1  1  1  1  0\n",
      "2  0  0  0  0\n",
      "3  1  1  0  1\n",
      "4  0  1  0  1\n",
      "5  1  0  1  1\n"
     ]
    }
   ],
   "source": [
    "dataA = [0, 1, 0, 1, 0, 1]\n",
    "dataB = [1, 1, 0, 1, 1, 0]\n",
    "dataC = [1, 1, 0, 0, 0, 1]\n",
    "dataY = [0, 0, 0, 1, 1, 1]\n",
    "dataAll = [dataA, dataB, dataC, dataY]\n",
    "dataAll = np.swapaxes(dataAll, 0, 1)\n",
    "df = pd.DataFrame(data=dataAll, columns=['A', 'B', 'C', 'Y'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy of output: 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "value,counts = np.unique(dataY, return_counts=True)\n",
    "entropyParent = entropy (counts)\n",
    "print(\"entropy of output: \" + str(entropyParent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Using the information gain criterion, what is the first node you would split at? Explain clearly why?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "child1=dict()\n",
    "child2=dict()\n",
    "entropy1=dict()\n",
    "entropy2=dict()\n",
    "weightedEntropy=dict()\n",
    "infoGain=dict()\n",
    "totalData=float(len(dataY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info gain for A: 0.05663301226513251\n"
     ]
    }
   ],
   "source": [
    "attr='A'\n",
    "\n",
    "child1[attr] = [2, 1]\n",
    "child2[attr] = [1, 2]\n",
    "entropy1[attr] = entropy(child1[attr])\n",
    "entropy2[attr] = entropy(child2[attr])\n",
    "\n",
    "weightedEntropy[attr] = (np.sum(child1[attr]) \n",
    "                         * entropy1[attr] \n",
    "                         + np.sum(child2[attr]) \n",
    "                         * entropy2[attr]) / totalData\n",
    "infoGain[attr] = entropyParent - weightedEntropy[attr]\n",
    "print(\"info gain for \"+ str(attr)+\": \" + str(infoGain[attr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info gain for B: 0.0\n"
     ]
    }
   ],
   "source": [
    "attr='B'\n",
    "\n",
    "child1[attr] = [1, 1]\n",
    "child2[attr] = [2, 2]\n",
    "entropy1[attr] = entropy(child1[attr])\n",
    "entropy2[attr] = entropy(child2[attr])\n",
    "\n",
    "weightedEntropy[attr] = (np.sum(child1[attr]) \n",
    "                         * entropy1[attr] \n",
    "                         + np.sum(child2[attr]) \n",
    "                         * entropy2[attr]) / totalData\n",
    "infoGain[attr] = entropyParent - weightedEntropy[attr]\n",
    "print(\"info gain for \"+ str(attr)+\": \" + str(infoGain[attr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info gain for C: 0.05663301226513251\n",
      "Hence, I will split at either A or C, as A and C both have higher information gain than B.\n"
     ]
    }
   ],
   "source": [
    "attr='C'\n",
    "\n",
    "child1[attr] = [1, 2]\n",
    "child2[attr] = [2, 1]\n",
    "entropy1[attr] = entropy(child1[attr])\n",
    "entropy2[attr] = entropy(child2[attr])\n",
    "\n",
    "weightedEntropy[attr] = (np.sum(child1[attr]) \n",
    "                         * entropy1[attr] \n",
    "                         + np.sum(child2[attr]) \n",
    "                         * entropy2[attr]) / totalData\n",
    "infoGain[attr] = entropyParent - weightedEntropy[attr]\n",
    "print(\"info gain for \"+ str(attr)+\": \" + str(infoGain[attr]))\n",
    "print(\"Hence, I will split at either A or C, as A and C both have higher information gain than B.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Using the information gain criterion, complete the learning of the decision tree for this dataset. Draw the decision tree and comment if the tree is unique.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['A',  'C']\n",
    "x = df[feature_cols] # Features\n",
    "y = df.Y # Target variable\n",
    "\n",
    "train = dict()\n",
    "test = dict()\n",
    "train['x'], test['x'], train['y'], test['y'] = train_test_split(x, y, test_size=0, random_state=1)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(train['x'],train['y'])\n",
    "\n",
    "#Predict the response for test dataset\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"269pt\" viewBox=\"0.00 0.00 436.00 269.00\" width=\"436pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-265 432,-265 432,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 0 -->\n",
       "<g class=\"node\" id=\"node1\"><title>0</title>\n",
       "<polygon fill=\"none\" points=\"260,-261 168,-261 168,-193 260,-193 260,-261\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214\" y=\"-245.8\">C &lt;= 0.5</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214\" y=\"-230.8\">entropy = 1.0</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214\" y=\"-215.8\">samples = 6</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214\" y=\"-200.8\">value = [3, 3]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1</title>\n",
       "<polygon fill=\"none\" points=\"205,-157 101,-157 101,-89 205,-89 205,-157\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-141.8\">A &lt;= 0.5</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-126.8\">entropy = 0.918</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-111.8\">samples = 3</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-96.8\">value = [1, 2]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>0-&gt;1</title>\n",
       "<path d=\"M194.195,-192.884C189.081,-184.332 183.508,-175.013 178.161,-166.072\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.051,-164.085 172.914,-157.299 175.043,-167.678 181.051,-164.085\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.816\" y=\"-177.844\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4</title>\n",
       "<polygon fill=\"none\" points=\"327,-157 223,-157 223,-89 327,-89 327,-157\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-141.8\">A &lt;= 0.5</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-126.8\">entropy = 0.918</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-111.8\">samples = 3</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-96.8\">value = [2, 1]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>0-&gt;4</title>\n",
       "<path d=\"M233.805,-192.884C238.919,-184.332 244.492,-175.013 249.839,-166.072\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"252.957,-167.678 255.086,-157.299 246.949,-164.085 252.957,-167.678\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261.184\" y=\"-177.844\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2</title>\n",
       "<polygon fill=\"none\" points=\"92,-53 0,-53 0,-0 92,-0 92,-53\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-37.8\">entropy = 1.0</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-22.8\">samples = 2</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-7.8\">value = [1, 1]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1-&gt;2</title>\n",
       "<path d=\"M115.577,-88.9485C104.908,-79.526 93.2987,-69.2731 82.675,-59.8906\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"84.9533,-57.2331 75.141,-53.2367 80.3195,-62.4798 84.9533,-57.2331\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g class=\"node\" id=\"node4\"><title>3</title>\n",
       "<polygon fill=\"none\" points=\"202,-53 110,-53 110,-0 202,-0 202,-53\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"156\" y=\"-37.8\">entropy = 0.0</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"156\" y=\"-22.8\">samples = 1</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"156\" y=\"-7.8\">value = [0, 1]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1-&gt;3</title>\n",
       "<path d=\"M154.049,-88.9485C154.311,-80.7153 154.592,-71.848 154.858,-63.4814\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"158.364,-63.3428 155.183,-53.2367 151.367,-63.1206 158.364,-63.3428\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g class=\"node\" id=\"node6\"><title>5</title>\n",
       "<polygon fill=\"none\" points=\"318,-53 226,-53 226,-0 318,-0 318,-53\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272\" y=\"-37.8\">entropy = 0.0</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272\" y=\"-22.8\">samples = 1</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272\" y=\"-7.8\">value = [1, 0]</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>4-&gt;5</title>\n",
       "<path d=\"M273.951,-88.9485C273.689,-80.7153 273.408,-71.848 273.142,-63.4814\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"276.633,-63.1206 272.817,-53.2367 269.636,-63.3428 276.633,-63.1206\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g class=\"node\" id=\"node7\"><title>6</title>\n",
       "<polygon fill=\"none\" points=\"428,-53 336,-53 336,-0 428,-0 428,-53\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382\" y=\"-37.8\">entropy = 1.0</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382\" y=\"-22.8\">samples = 2</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382\" y=\"-7.8\">value = [1, 1]</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>4-&gt;6</title>\n",
       "<path d=\"M312.423,-88.9485C323.092,-79.526 334.701,-69.2731 345.325,-59.8906\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"347.681,-62.4798 352.859,-53.2367 343.047,-57.2331 347.681,-62.4798\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "\n",
    "from sklearn import tree\n",
    "Source( tree.export_graphviz(clf, out_file=None, feature_names=feature_cols))\n",
    "from IPython.display import SVG\n",
    "graph = Source( tree.export_graphviz(clf, out_file=None, feature_names=feature_cols))\n",
    "SVG(graph.pipe(format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree is not unique, as the root node can either be A or C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2-3: Plot the training points and, by inspection, draw a linear classifier that separates the\n",
    "data with maximum margin.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "negClass = [[1,5],[1,6],[3,3]]\n",
    "\n",
    "posClass = [[-1,3],[0,2],[0,1],[0,0]]\n",
    "negClass=np.array(negClass)\n",
    "posClass=np.array(posClass)\n",
    "\n",
    "labels=[0,0,0,1,1,1,1]\n",
    "\n",
    "# data =dict()\n",
    "# data['x'] = np.concatenate((negClass[:,0],posClass[:,0]),axis=0)\n",
    "# data['y'] = np.concatenate((negClass[:,1],posClass[:,1]),axis=0)\n",
    "\n",
    "# print(data['x'])\n",
    "# print(data['y'])\n",
    "# graph=plt.scatter(data['x'],data['y'])\n",
    "# plt.grid()\n",
    "# plt.xlabel(\"x\")\n",
    "# plt.ylabel(\"y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots(1,1)\n",
    "ax.scatter(negClass[:,0], negClass[:,1], marker='^')\n",
    "ax.scatter(posClass[:,0], posClass[:,1], marker='o')\n",
    "ax.plot([-1,3],[5,1])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5]\n",
      " [ 1  6]\n",
      " [ 3  3]\n",
      " [-1  3]\n",
      " [ 0  2]\n",
      " [ 0  1]\n",
      " [ 0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "X_train=np.concatenate((negClass,posClass),axis=0)\n",
    "print(X_train)\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, labels)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The linear SVM is parameterized by h(x) = (w^t)(x) + b. What are the parameters w\n",
    "and b for this problem?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: w is a vector whose direction is perpendicular to the line representing the linear classifier. b is the amount of displacement of the linear classifier from the origin.\n",
    "\n",
    "w^T * (-1-3,5-1) = w^T * (-1,1) * 4 =0\n",
    "\n",
    "Hence, w = (1,1), |w| = sqrt(2)\n",
    "\n",
    "Let a point on the hyperline be xi=(-1,5)\n",
    "\n",
    "w^T * xi + b = 4 + b = 0\n",
    "\n",
    "Hence, b = 4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "newData=[[-2,0],[-2,1],[-2,3],[-1,0],[-1,1],[0,0]]\n",
    "newData=np.array(newData)\n",
    "fig,ax=plt.subplots(1,1)\n",
    "ax.scatter(negClass[:,0], negClass[:,1], marker='^')\n",
    "ax.scatter(posClass[:,0], posClass[:,1], marker='o')\n",
    "ax.scatter(newData[:,0], newData[:,1], marker='x')\n",
    "ax.plot([-1,3],[5,1])\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No change in w or b, i.e. w is still (1,1) and b is still 4, because the nearest data points to the hyperline remain the same two data points as before, i.e. points (0,2) and (1,5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2-4: Is it possible that Classifier 1 has higher accuracy than Classifier 2, but Classifier 2 has both higher precision and higher recall than Classifier 1?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, it is possible.\n",
      "\n",
      "------------------------------\n",
      "Table1\n",
      "           0_actual  1_actual\n",
      "0_predict      95.0       2.0\n",
      "1_predict       3.0       0.0\n",
      "\n",
      "accuracy: 0.95 \n",
      "precision: 0.00 \n",
      "recall: 0.00\n",
      "------------------------------\n",
      "Table2\n",
      "           0_actual  1_actual\n",
      "0_predict      25.0      25.0\n",
      "1_predict      25.0      25.0\n",
      "\n",
      "accuracy: 0.50 \n",
      "precision: 0.50 \n",
      "recall: 0.50\n",
      "------------------------------\n",
      "Hence, table2 has higher precision and recall but lower accuracy than table 1.\n"
     ]
    }
   ],
   "source": [
    "print(\"Yes, it is possible.\\n\")\n",
    "[tn1,fn1,fp1,tp1]=np.array([95,2,3,0]).astype(float)\n",
    "[tn2,fn2,fp2,tp2]=np.array([25,25,25,25]).astype(float)\n",
    "total1=tn1 + fn1 + fp1 + tp1\n",
    "total2=tn2 + fn2 + fp2 + tp2\n",
    "table1 = pd.DataFrame([[tn1,fn1],[fp1,tp1]],columns=[\"0_actual\",\"1_actual\"],index=[\"0_predict\",\"1_predict\"])\n",
    "table2 = pd.DataFrame([[tn2,fn2],[fp2,tp2]],columns=[\"0_actual\",\"1_actual\"],index=[\"0_predict\",\"1_predict\"])\n",
    "print(\"-\"*30)\n",
    "print(\"Table1\")\n",
    "print(table1)\n",
    "accuracy=(tp1+tn1)/total1\n",
    "precision=tp1/(tp1+fp1)\n",
    "recall=tp1/(tp1+fn1)\n",
    "print(\"\\naccuracy: {:.2f} \\nprecision: {:.2f} \\nrecall: {:.2f}\".format(accuracy,precision,recall))\n",
    "print(\"-\"*30)\n",
    "print(\"Table2\")\n",
    "print(table2)\n",
    "accuracy=(tp2+tn2)/total2\n",
    "precision=tp2/(tp2+fp2)\n",
    "recall=tp2/(tp2+fn2)\n",
    "print(\"\\naccuracy: {:.2f} \\nprecision: {:.2f} \\nrecall: {:.2f}\".format(accuracy,precision,recall))\n",
    "print(\"-\"*30)\n",
    "print(\"Hence, table2 has higher precision and recall but lower accuracy than table 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2-5: Compute the performance of various machine learning algorithms (see below) on this\n",
    "dataset for predicting the whether the diagnosis is malignant or benign.***\n",
    "\n",
    "Use a random split of 70% of the data for training and 30% for testing. Repeat this process 20 times and compute the average performance for both the training and testing stages.\n",
    "Algorithms:\n",
    "\n",
    "• DT1: Decision Tree with Information Gain\n",
    "\n",
    "• DT2: Same as DT1 with limited tree size, vary the number of levels to beat DT1 if you can.\n",
    "\n",
    "• SVM1: SVM with linear kernel\n",
    "\n",
    "• SVM2: SVM with RBF kernel\n",
    "\n",
    "• SVM3: Same as SVM2 but with regularization (soft margin), Choose C to beat SVM1 and SVM2 if you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAttr=[\"Sample code number\"\n",
    "           ,\"Clump Thickness\"\n",
    "           ,\"Uniformity of Cell Size\"\n",
    "           ,\"Uniformity of Cell Shape\"\n",
    "           ,\"Marginal Adhesion\"\n",
    "           ,\"Single Epithelial Cell Size\"\n",
    "           ,\"Bare Nuclei\"\n",
    "           ,\"Bland Chromatin\"\n",
    "           ,\"Normal Nucleoli\"\n",
    "           ,\"Mitoses\"\n",
    "           ,\"Class\"]\n",
    "\n",
    "df = pd.read_csv(\"breast-cancer-wisconsin.data\",delimiter=\",\",header=None)\n",
    "# df2 = df.rename(columns={0:\"id\"})\n",
    "# print(df2)\n",
    "resColLabels=[\"trainAccu\",\"testAccu\",\"precision\",\"recall\"]\n",
    "resRowLabels=[\"DT1\",\"DT2\",\"SVM1\",\"SVM2\",\"SVM3\"]\n",
    "resultsTable=pd.DataFrame(columns=resColLabels,index=resRowLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     trainAccu  testAccu precision    recall\n",
      "DT1          1  0.948571  0.969774  0.879452\n",
      "DT2        NaN       NaN       NaN       NaN\n",
      "SVM1       NaN       NaN       NaN       NaN\n",
      "SVM2       NaN       NaN       NaN       NaN\n",
      "SVM3       NaN       NaN       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "x=df.iloc[:,1:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "x=x.astype(int)\n",
    "y=y.astype(int)\n",
    "\n",
    "train = dict()\n",
    "test = dict()\n",
    "# train['x'], test['x'], train['y'], test['y'] = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "accuTrain=[]\n",
    "accuTest=[]\n",
    "prec=[]\n",
    "recall=[]\n",
    "\n",
    "for epoch in range(20):\n",
    "    train['x'], test['x'], train['y'], test['y'] = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(train['x'],train['y'])\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_train = clf.predict(train['x'])\n",
    "    accuTrain.append(metrics.accuracy_score(train['y'], y_pred_train))\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(test['x'])\n",
    "    accuTest.append(metrics.accuracy_score(test['y'], y_pred))\n",
    "    prec.append(metrics.precision_score(test['y'], y_pred,pos_label=4))\n",
    "    recall.append(metrics.recall_score(test['y'], y_pred,pos_label=4))\n",
    "    \n",
    "mAccuTrain=np.mean(accuTrain)\n",
    "mAccuTest=np.mean(accuTest)\n",
    "mPrec=np.mean(prec)\n",
    "mRecall=np.mean(recall)\n",
    "# print(\"Accuracy (train):\"+mAccuTrain)\n",
    "# print(\"Accuracy (test):\"+mAccuTest)\n",
    "# print(\"Precision (4=positive):\"+mPrec)\n",
    "# print(\"Recall (4=positive):\"+mRecall)\n",
    "algorithm=\"DT1\"\n",
    "resultsTable.loc[algorithm][\"trainAccu\"]=mAccuTrain\n",
    "resultsTable.loc[algorithm][\"testAccu\"]=mAccuTest\n",
    "resultsTable.loc[algorithm][\"precision\"]=mPrec\n",
    "resultsTable.loc[algorithm][\"recall\"]=mRecall\n",
    "resultsTable=resultsTable.round(3)\n",
    "print(resultsTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we limit the depth of the tree.\n",
      "     trainAccu  testAccu precision    recall\n",
      "DT1          1  0.948571  0.969774  0.879452\n",
      "DT2   0.977505  0.947619  0.930556  0.917808\n",
      "SVM1       NaN       NaN       NaN       NaN\n",
      "SVM2       NaN       NaN       NaN       NaN\n",
      "SVM3       NaN       NaN       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"Now we limit the depth of the tree.\")\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\",max_depth=5)\n",
    "\n",
    "accuTrain=[]\n",
    "accuTest=[]\n",
    "prec=[]\n",
    "recall=[]\n",
    "\n",
    "for epoch in range(20):\n",
    "    train['x'], test['x'], train['y'], test['y'] = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(train['x'],train['y'])\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_train = clf.predict(train['x'])\n",
    "    accuTrain.append(metrics.accuracy_score(train['y'], y_pred_train))\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(test['x'])\n",
    "    accuTest.append(metrics.accuracy_score(test['y'], y_pred))\n",
    "    prec.append(metrics.precision_score(test['y'], y_pred,pos_label=4))\n",
    "    recall.append(metrics.recall_score(test['y'], y_pred,pos_label=4))\n",
    "    \n",
    "mAccuTrain=np.mean(accuTrain)\n",
    "mAccuTest=np.mean(accuTest)\n",
    "mPrec=np.mean(prec)\n",
    "mRecall=np.mean(recall)\n",
    "# print(\"Accuracy (train):\"+mAccuTrain)\n",
    "# print(\"Accuracy (test):\"+mAccuTest)\n",
    "# print(\"Precision (4=positive):\"+mPrec)\n",
    "# print(\"Recall (4=positive):\"+mRecall)\n",
    "algorithm=\"DT2\"\n",
    "resultsTable.loc[algorithm][\"trainAccu\"]=mAccuTrain\n",
    "resultsTable.loc[algorithm][\"testAccu\"]=mAccuTest\n",
    "resultsTable.loc[algorithm][\"precision\"]=mPrec\n",
    "resultsTable.loc[algorithm][\"recall\"]=mRecall\n",
    "# resultsTable=resultsTable.round(3)\n",
    "print(resultsTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "     trainAccu  testAccu precision    recall\n",
      "DT1          1  0.948571  0.969774  0.879452\n",
      "DT2   0.977505  0.947619  0.930556  0.917808\n",
      "SVM1  0.965235  0.971429  0.971831  0.945205\n",
      "SVM2       NaN       NaN       NaN       NaN\n",
      "SVM3       NaN       NaN       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVM\")\n",
    "# Create linear SVM object\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "accuTrain=[]\n",
    "accuTest=[]\n",
    "prec=[]\n",
    "recall=[]\n",
    "\n",
    "for epoch in range(20):\n",
    "    train['x'], test['x'], train['y'], test['y'] = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(train['x'],train['y'])\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_train = clf.predict(train['x'])\n",
    "    accuTrain.append(metrics.accuracy_score(train['y'], y_pred_train))\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(test['x'])\n",
    "    accuTest.append(metrics.accuracy_score(test['y'], y_pred))\n",
    "    prec.append(metrics.precision_score(test['y'], y_pred,pos_label=4))\n",
    "    recall.append(metrics.recall_score(test['y'], y_pred,pos_label=4))\n",
    "    \n",
    "mAccuTrain=np.mean(accuTrain)\n",
    "mAccuTest=np.mean(accuTest)\n",
    "mPrec=np.mean(prec)\n",
    "mRecall=np.mean(recall)\n",
    "# print(\"Accuracy (train):\"+mAccuTrain)\n",
    "# print(\"Accuracy (test):\"+mAccuTest)\n",
    "# print(\"Precision (4=positive):\"+mPrec)\n",
    "# print(\"Recall (4=positive):\"+mRecall)\n",
    "algorithm=\"SVM1\"\n",
    "resultsTable.loc[algorithm][\"trainAccu\"]=mAccuTrain\n",
    "resultsTable.loc[algorithm][\"testAccu\"]=mAccuTest\n",
    "resultsTable.loc[algorithm][\"precision\"]=mPrec\n",
    "resultsTable.loc[algorithm][\"recall\"]=mRecall\n",
    "resultsTable=resultsTable.round(3)\n",
    "print(resultsTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM\n",
      "     trainAccu  testAccu precision    recall\n",
      "DT1          1  0.948571  0.969774  0.879452\n",
      "DT2   0.977505  0.947619  0.930556  0.917808\n",
      "SVM1  0.965235  0.971429  0.971831  0.945205\n",
      "SVM2  0.993865  0.961905  0.901235         1\n",
      "SVM3       NaN       NaN       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"RBF SVM\")\n",
    "# Create linear SVM object\n",
    "clf = svm.SVC(kernel='rbf') # Linear Kernel\n",
    "\n",
    "accuTrain=[]\n",
    "accuTest=[]\n",
    "prec=[]\n",
    "recall=[]\n",
    "\n",
    "for epoch in range(20):\n",
    "    train['x'], test['x'], train['y'], test['y'] = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(train['x'],train['y'])\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_train = clf.predict(train['x'])\n",
    "    accuTrain.append(metrics.accuracy_score(train['y'], y_pred_train))\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(test['x'])\n",
    "    accuTest.append(metrics.accuracy_score(test['y'], y_pred))\n",
    "    prec.append(metrics.precision_score(test['y'], y_pred,pos_label=4))\n",
    "    recall.append(metrics.recall_score(test['y'], y_pred,pos_label=4))\n",
    "    \n",
    "mAccuTrain=np.mean(accuTrain)\n",
    "mAccuTest=np.mean(accuTest)\n",
    "mPrec=np.mean(prec)\n",
    "mRecall=np.mean(recall)\n",
    "# print(\"Accuracy (train):\"+mAccuTrain)\n",
    "# print(\"Accuracy (test):\"+mAccuTest)\n",
    "# print(\"Precision (4=positive):\"+mPrec)\n",
    "# print(\"Recall (4=positive):\"+mRecall)\n",
    "algorithm=\"SVM2\"\n",
    "resultsTable.loc[algorithm][\"trainAccu\"]=mAccuTrain\n",
    "resultsTable.loc[algorithm][\"testAccu\"]=mAccuTest\n",
    "resultsTable.loc[algorithm][\"precision\"]=mPrec\n",
    "resultsTable.loc[algorithm][\"recall\"]=mRecall\n",
    "resultsTable=resultsTable.round(3)\n",
    "print(resultsTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with soft margin\n",
      "     trainAccu  testAccu precision    recall\n",
      "DT1          1  0.948571  0.969774  0.879452\n",
      "DT2   0.977505  0.947619  0.930556  0.917808\n",
      "SVM1  0.965235  0.971429  0.971831  0.945205\n",
      "SVM2  0.993865  0.961905  0.901235         1\n",
      "SVM3   0.96728  0.957143  0.890244         1\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM with soft margin\")\n",
    "# Create linear SVM object\n",
    "clf = svm.SVC(C=0.6,kernel='rbf') # Linear Kernel\n",
    "\n",
    "accuTrain=[]\n",
    "accuTest=[]\n",
    "prec=[]\n",
    "recall=[]\n",
    "\n",
    "for epoch in range(20):\n",
    "    train['x'], test['x'], train['y'], test['y'] = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "    clf = clf.fit(train['x'],train['y'])\n",
    "\n",
    "    y_pred_train = clf.predict(train['x'])\n",
    "    accuTrain.append(metrics.accuracy_score(train['y'], y_pred_train))\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(test['x'])\n",
    "    accuTest.append(metrics.accuracy_score(test['y'], y_pred))\n",
    "    prec.append(metrics.precision_score(test['y'], y_pred,pos_label=4))\n",
    "    recall.append(metrics.recall_score(test['y'], y_pred,pos_label=4))\n",
    "    \n",
    "mAccuTrain=np.mean(accuTrain)\n",
    "mAccuTest=np.mean(accuTest)\n",
    "mPrec=np.mean(prec)\n",
    "mRecall=np.mean(recall)\n",
    "algorithm=\"SVM3\"\n",
    "resultsTable.loc[algorithm][\"trainAccu\"]=mAccuTrain\n",
    "resultsTable.loc[algorithm][\"testAccu\"]=mAccuTest\n",
    "resultsTable.loc[algorithm][\"precision\"]=mPrec\n",
    "resultsTable.loc[algorithm][\"recall\"]=mRecall\n",
    "resultsTable=resultsTable.round(3)\n",
    "print(resultsTable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
